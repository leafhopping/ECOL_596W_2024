---
title: "Week_7B_Regression_AnswerKey"
author: "Sabrina McNew"
date: "2023-10-05"
output: html_document
---
## Week 7: Regression   
Answer key.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message= FALSE}
# Load packages 

library(ggplot2)
library(ggthemr)
library(tidyr)
library(palmerpenguins)
library(emmeans)
library(dplyr) #load last to avoid conflicts between packages

# Set graphing parameters (optional), see ggthemr website for options
ggthemr(palette = "grape", layout = "clean", text_size = 22)

# Load data:
penguins <- penguins

# filter out nas
penguins <- filter(penguins, !is.na(flipper_length_mm))
```


### Problem 1:  
What is the relationship between flipper length and body size
in penguins?

1a: Create a plot showing this relationship
```{r}
# base plot
plot(body_mass_g ~ flipper_length_mm, data = penguins)

## or ggplot
penguins %>% ggplot(aes(x = flipper_length_mm, y = body_mass_g)) + geom_point()

```

1b: What is the correlation coefficient between these variables? 
Notes: sometimes for base r functions you'll get an NA when you don't expect one.
Usually this means you have missing data in your dataframe. Read the help info
for the function to determine how to deal with it. A common argument is na.rm = TRUE. In this case, cor() takes an argument "use = " that has various options. 
```{r}
cor(penguins$flipper_length_mm, penguins$body_mass_g, use = "complete.obs")
```


1c: Create a linear model and send it to an object (e.g. mod1 <- lm(...)). Notes: 
we don't have an obvious biological reason to make one x or y but let's do mass on the x
```{r}
mod1 <- lm(flipper_length_mm ~ body_mass_g, data = penguins) #remember y ~ x
```

1d: Is body mass significantly associated with flipper length?
```{r}
summary(mod1)
```
Yes, Pr(>|t|) < 2e-16 means that body_mass_g significantly predicts flipper length.  
1e: Let's put this model to work. Say you catch a 4000 gram penguin. How long
do you think it's flipper will be? Calculate the value using the model coeffs.
what is the equation of the model line?
```{r}
# we can either extract the coefficients from the summary table or like this: 
mod1$coefficients
0.01527592 * 4000 + 136.72955927 # 4000 * slope + intercept

# another option
mod1$coefficients["body_mass_g"]*4000 + mod1$coefficients["(Intercept)"]
```


 1f: R will also calculated predicted values of Y for us, using the predict()
function. Read the documentation of this function and try to figure out how it works.
Use predict() to predict the ys for a set of four penguins with mass (2120,
5780, 4700, and 8001)
```{r}
new_mass <- data.frame(body_mass_g = c(2120, 5780, 4700, 8001))
predict(mod1, new_mass)
```


1g: What is the r squared value of your model? How do you interpret this value?
How is this value related to the correlation coefficient?
```{r}
summary(mod1) # it's visible at the bottom of the summary 
summary(mod1)$adj.r.squared #or, access the number directly 
```
Adjusted R-squared:  0.7583 

1h: Inspect your residuals. What do you see in the model output? What do you see if you look at the qqplot of residuals? (e.g. plot(mod1))
```{r}
plot(mod1)
```
There's a fair bit of information in these plots. Let's just focus on the Q-Q plot.
This tells us for all our predicted values along the range of x ("Theoretical quantiles) how far away were our observed values ("Standardized residuals"). 
Remember that residuals should be centered at 0 and normally distributed. This 
Q-Q plot overall looks pretty good, but our observed values tended to be less 
than expected at the upper end of our mass range. As we discussed in class, this is most likely because at that upper end of mass range we change species of penguin,
and the relationship between mass and flipper length shifts slightly.  
So this type of QQ plot could tell you there's some unmodeled variation in your data but the fact that most of the points fall on that line suggests that overall 
this model is decent.

1i: Let's compare our predicted y values (from the model) to our real y values
First, create a vector of predicted ys called "predicted_flipper" and add
it to your data frame (use the predict() function). Then, create a scatter plot
where the x is the true flipper length and y is the predicted flipper length.
Finally, add a 1:1 line using geom_abline(intercept = 0, slope = 1).
How do you interpret this graph?

```{r}
# ask it to predict Y values based on mod1 for penguins. It will find the x 
# in penguins based on the x column that matches the term in the model. I.e. 
# the model has "body_mass_g" as the predictor term. So it uses # penguins$body_mass_g as x values to plug into the model. 
penguins$predicted_flipper <- predict(mod1, penguins)

penguins %>% ggplot(aes(x = flipper_length_mm, y = predicted_flipper)) +
  geom_point() + geom_abline(intercept = 0, slope = 1)


```
If our model works, the residuals should be centered on 0 and symmetric around the mean. This means that some of our observed points will fall below the 1:1 line,
some will fall above it, but they should be relatively scattered along this line. The relative sparseness of points above the line at the upper end of the scale reflects why the QQ plot was dragging down at the upper end of the scale. The observed points were less than predicted. 

1h: What happens if you scale the x variable in your plot and lm? (e.g. use scale())
```{r}
penguins$scaled_body_mass_g <- scale(penguins$body_mass_g)
#alternate dplyr syntax: penguins <- penguins %>% mutate (scaled_body_mass_g = scale(body_mass_g))

lm(flipper_length_mm ~ scaled_body_mass_g, data = penguins) |> summary()
```
Notes: The model is very similar. The P values and R2 are all the same. The slope
However, the coefficients have changed because the X is now on a different scale.
Let's take a look: 

```{r}
penguins %>% ggplot(aes(x = scaled_body_mass_g, y = flipper_length_mm)) + geom_point()
```
Note, the graph looks exactly the same, but the x axis has shifted. What does 
scale() do? First, it centers the data, which means it subtracts mean(x) from every value of x. Thus, points that are near the mean value become 0s, values smaller
than the mean become negative, etc. Then, it scales the x, which means x values get divided by the standard deviation. Thus, a scaled point = 2 is a point that is two 
standard deviations from the mean. 

Why would scaling help interpretation in this case?
Scaling can be useful if you want to interpret coefficients relative to a "mean" 
case. It can also be useful if you have multiple predictor variables on very different scales. 

Problem 2: Body size of penguins may also vary between sexes. Create a boxplot
to look at mass of males and females of the three species.

2a: Annoying! there are NAs here too. Potentially juveniles? Find a way to
filter them out.
```{r}
penguins <- na.omit(penguins)
penguins %>% ggplot(aes(y = body_mass_g, x = sex)) + geom_boxplot()
```


2b: Create a linear model testing for differences in mass between males and females
(without separating species). Create a separate linear model testing for differences in mass between species. What are the results of these models? How do you interpret their outputs?


```{r}
# note, if I'm just messing around with models that are quick and simple to 
# run I often won't save them to the environment 
lm(body_mass_g ~ sex, data = penguins) %>% summary()

```
Males are significantly larger than females. 

```{r}
lm(body_mass_g ~ species, data = penguins) %>% summary()
```
Chinstraps weigh on average more than Adelie penguins (note positive coeff); however, the difference is not significant (P = 0.69). Gentoos weigh significantly
more than Adelies (by a lot!).

2c: Create a multiple regression model that includes both the effects of sex
and species on body mass. What is the R squared value of this model compared to the
single variable regression models? How do you interpret these coefficients?

```{r}
mod2 <- lm(body_mass_g ~ sex, data = penguins)
mod3 <- lm(body_mass_g ~ sex + species, data = penguins)
summary(mod2)$adj.r.squared # medium
summary(mod3)$adj.r.squared # much higher!

```

2d: Use the emmeans::emmeans() and emmeans::pairs() functions to do post-hoc
comparisons between groups. Emmeans is a big package with a lot of options,
consult a couple of help pages to orient yourself to things you can do with it.

e.g. https://aosmith.rbind.io/2019/03/25/getting-started-with-emmeans/
https://cran.r-project.org/web/packages/emmeans/vignettes/comparisons.html

```{r}
mod3 %>% emmeans(specs = "species") %>% pairs
mod3 %>% emmeans(specs = c("species", "sex")) %>% pairs
```

### Problem 3: 
Adelie penguins were sampled on three different islands. Does the
size of Adelies differ significantly among islands? Create plots and lm
to answer this question. Interpret the coefficients in your lm output
```{r}
penguins %>% filter(species == "Adelie") %>% 
  ggplot(aes(x = island, y = body_mass_g)) + geom_boxplot()
```
Plot is not super convincing that they're different... let's see what the model says 

```{r}
lm(body_mass_g ~ island, data = penguins[penguins$species == "Adelie",]) %>% summary

#alternative tidy syntax: note the "." to indicate where the piped dataframe should 'land'
penguins %>% filter(species == "Adelie") %>%
  lm(body_mass_g ~ island, data = .) %>% summary()
```
Yup, no real evidence of difference (P > 0.05) for all comparisons. I won't bother
to do a post-hoc test in a case like this.  

### Problem 4: 
Create a new dataset called penguins2 that does not have Adelie penguins. Say you want to test whether the mass of gentoo penguins is significantly
different from that of chinstrap penguins. Use a t.test and a lm to answer
this question. Compare the output. Where is the output of the tests similar? Where is it different?

```{r}
penguins2 <- penguins %>% filter(species != "Adelie")
lm(body_mass_g ~ species, data = penguins2) %>% summary()
t.test(body_mass_g ~ species, data = penguins2)
```
The results here are pretty similar: at least they get to the same conclusion. 
Both tests determine that Gentoos are significantly larger than Chinstraps. Relevant info from the t.test is:  
* mean in group Chinstrap = 3733; mean in group Gentoo = 5092
* t = -20.765, df = 169.62, p-value < 2.2e-16

Relevant info from lm: 
* mean in group Chinstrap (intercept) = 3733; mean in group Gentoo = 3733 + 1359
* t = 19.34, df = 185, p < 2.2e-16. 

Why are they different? dim(penguins2) tells us there are 187
rows, so df = 185 makes sense for the lm. R's t-test is a little fancy, it adds some extra twists to accomodate samples with unequal variances. That's why it "approximates" dfs rather than give the standard N-2. Otherwise they're very similar. The p values give us the same exact answer. 

```{r}
sjPlot::tab_model(mod2)

```


      